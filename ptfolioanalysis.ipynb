{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHXgoJXpIQ08zcSPO/jiJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buzman92/gpt2lab/blob/main/ptfolioanalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpwVoDKrrJwp"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "S5LYtCqtrUzn",
        "outputId": "e28937d7-85ac-4851-cd66-3cdc2f02bdbd"
      },
      "source": [
        "# Load tradesheet\n",
        "trades = pd.read_csv('tradesheet.csv', index_col=0)\n",
        "trades.index = pd.to_datetime(trades.index)\n",
        "\n",
        "# Determine traded tickers excluding FIAT\n",
        "fiat = 'usd'\n",
        "tickers = list(set(trades['Buy']))\n",
        "tickers = [ticker.lower() for ticker in tickers if ticker.lower() != fiat]\n",
        "\n",
        "# Assume market data column order\n",
        "column_names = ['Date', 'Close Price', 'Market Cap', 'Volume']\n",
        "\n",
        "# Load market data initially retrieved from www.coingecko.com\n",
        "market_data = {}\n",
        "for filename in os.listdir('data'):\n",
        "    ticker = filename.split('-')[0].lower()\n",
        "    \n",
        "    # Skip unused tickers\n",
        "    if ticker not in tickers:\n",
        "        continue\n",
        "    \n",
        "    file_data = pd.read_csv('data' + os.sep + filename)\n",
        "\n",
        "    # Rename columns\n",
        "    curr_column_names = list(file_data)\n",
        "    column_names_map = {curr_column_names[i]: column_names[i] for i in range(len(column_names))}\n",
        "    file_data.rename(columns=column_names_map, inplace=True)\n",
        "    \n",
        "    # Set index to date and convert to np.datetime64\n",
        "    file_data.set_index(['Date'], inplace=True)\n",
        "    file_data.index = pd.to_datetime(file_data.index)  \n",
        "    \n",
        "    market_data[ticker] = file_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a10f7d509ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load market data initially retrieved from www.coingecko.com\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmarket_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnNX1jfCrV4K"
      },
      "source": [
        "# Determine the valid trade dates\n",
        "start_date = min(trades.index.values)\n",
        "end_date = max([max(data.index.values) for _, data in market_data.items()])\n",
        "trade_dates = np.arange(start_date, end_date + np.timedelta64(1, 'D'), np.timedelta64(1, 'D'))\n",
        "\n",
        "# Make sure the first trade record is a cash deposit\n",
        "if not np.isnan(trades.iloc[0]['Sell']):\n",
        "    raise ValueError('The first row of your tradesheet must be a cash deposit.')\n",
        "\n",
        "# Intialize holdings and asset performance\n",
        "holdings = {ticker: 0.0 for ticker in tickers}\n",
        "holdings[fiat] = trades.iloc[0]['Units']\n",
        "asset_performance = {trade_date: {ticker: 0.0 for ticker in tickers} for trade_date in trade_dates}\n",
        "\n",
        "# Remove initial cash deposit from trades\n",
        "actual_trades = trades.iloc[1:]\n",
        "\n",
        "# Update holdings based on trade\n",
        "def update_holdings(trade, holdings):\n",
        "    # Avoid NaN cells during FIAT deposits and withdrawls\n",
        "    if not pd.isnull(trade['Sell']):\n",
        "        holdings[trade['Sell'].lower()] -= trade['Units'] * trade['Value Per Unit']\n",
        "    if not pd.isnull(trade['Buy']):\n",
        "        holdings[trade['Buy'].lower()] += trade['Units']\n",
        "        \n",
        "# Walk forward each day, execute trading strategy, and record performance\n",
        "for trade_date in trade_dates:\n",
        "    # Update holdings based on today's trade(s)\n",
        "    if trade_date in actual_trades.index:\n",
        "        todays_trades = actual_trades.loc[trade_date]\n",
        "        \n",
        "        if type(todays_trades) is pd.DataFrame:\n",
        "            # Multiple trades occurred today\n",
        "            for i in range(len(todays_trades)):\n",
        "                update_holdings(todays_trades.iloc[i], holdings)\n",
        "        else:\n",
        "            # Single trade occurred today\n",
        "            update_holdings(todays_trades, holdings)\n",
        "    \n",
        "    # Mark-to-market portfolio\n",
        "    for ticker in tickers:\n",
        "        if trade_date in market_data[ticker].index:\n",
        "            asset_performance[trade_date][ticker] = \\\n",
        "                holdings[ticker] * market_data[ticker].loc[trade_date]['Close Price']\n",
        "        else:\n",
        "            # Fill missing data\n",
        "            if trade_date > start_date:\n",
        "                asset_performance[trade_date][ticker] = \\\n",
        "                    asset_performance[trade_date - np.timedelta64(1, 'D')][ticker]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd1xdNimrZAW"
      },
      "source": [
        "# Get the portfolio and benchmark performances (doesn't adjust for cash flows)\n",
        "benchmark_performance = market_data['btc']['Close Price']\n",
        "benchmark_performance = benchmark_performance[benchmark_performance.index >= start_date]\n",
        "portfolio_performance = pd.DataFrame(index=trade_dates, columns=['Value'])\n",
        "for date, assets in asset_performance.items():\n",
        "    portfolio_performance['Value'].loc[date] = sum([value for ticker, value in assets.items()])\n",
        "\n",
        "# Compute arithmetic and geometric returns\n",
        "a_returns = portfolio_performance.pct_change().dropna()\n",
        "g_returns = np.log(a_returns + 1)\n",
        "benchmark_a_returns = benchmark_performance.pct_change().dropna()\n",
        "benchmark_g_returns = np.log(benchmark_a_returns + 1)\n",
        "\n",
        "# Record cash flows (not including first deposit) and adjust returns and end portfolio value\n",
        "# NOTE: This is not the most accurate way to adjust for cash flows, but it helps\n",
        "cash_flows = {}\n",
        "for trade_date in trade_dates:\n",
        "    if trade_date in actual_trades.index:\n",
        "        todays_trades = actual_trades.loc[trade_date]\n",
        "        \n",
        "        if type(todays_trades) is pd.DataFrame:\n",
        "            # Multiple trades occurred today\n",
        "            for i in range(len(todays_trades)):\n",
        "                if not pd.isnull(todays_trades['Buy'].iloc[i]) and pd.isnull(todays_trades['Sell'].iloc[i]):\n",
        "                    cash_flows[trade_date] = -todays_trades['Units'].iloc[i]\n",
        "                elif pd.isnull(todays_trades['Buy'].iloc[i]) and not pd.isnull(todays_trades['Sell'].iloc[i]):\n",
        "                    cash_flows[trade_date] = todays_trades['Units'].iloc[i]\n",
        "        else:\n",
        "            # Single trade occurred today\n",
        "            if not pd.isnull(todays_trades['Buy']) and pd.isnull(todays_trades['Sell']):\n",
        "                cash_flows[trade_date] = -todays_trades['Units']\n",
        "            elif pd.isnull(todays_trades['Buy']) and not pd.isnull(todays_trades['Sell']):\n",
        "                cash_flows[trade_date] = todays_trades['Units']\n",
        "\n",
        "a_returns.drop(cash_flows.keys(), inplace=True)\n",
        "g_returns.drop(cash_flows.keys(), inplace=True)\n",
        "neg_g_returns = g_returns[g_returns < 0].dropna()\n",
        "benchmark_neg_g_returns = benchmark_g_returns[benchmark_g_returns < 0].dropna()\n",
        "benchmark_g_returns.drop(cash_flows.keys(), inplace=True)\n",
        "adjusted_end_value = portfolio_performance['Value'].loc[end_date] + np.sum(list(cash_flows.values()))\n",
        "\n",
        "# Compute benchmark statistics\n",
        "benchmark_total_return = (benchmark_performance[end_date] / benchmark_performance[start_date]) - 1\n",
        "benchmark_annualized_return = 365 * benchmark_g_returns.mean()\n",
        "benchmark_annualized_volatility = np.sqrt(365) * benchmark_g_returns.std()\n",
        "benchmark_annualized_downside_risk = np.sqrt(365) * benchmark_neg_g_returns.std()\n",
        "benchmark_sharpe_ratio = benchmark_annualized_return / benchmark_annualized_volatility\n",
        "benchmark_sortino_ratio = benchmark_annualized_return / benchmark_annualized_downside_risk\n",
        "benchmark_cagr = ((benchmark_performance[end_date] / benchmark_performance[start_date]) \\\n",
        "                  ** (1 / (len(trade_dates) / 365))) - 1\n",
        "\n",
        "# Compute portfolio statistics\n",
        "total_return = (adjusted_end_value / portfolio_performance['Value'].loc[start_date]) - 1\n",
        "annualized_return = 365 * g_returns.mean()\n",
        "annualized_volatility = np.sqrt(365) * g_returns.std()\n",
        "annualized_downside_risk = np.sqrt(365) * neg_g_returns.std()\n",
        "sharpe_ratio = annualized_return / annualized_volatility\n",
        "sortino_ratio = annualized_return / annualized_downside_risk\n",
        "cagr = ((adjusted_end_value / portfolio_performance['Value'].loc[start_date]) \\\n",
        "        ** (1 / (len(trade_dates) / 365))) - 1\n",
        "covariance_matrix = pd.concat([g_returns['Value'], benchmark_g_returns], axis=1).dropna().cov()\n",
        "beta = covariance_matrix.iloc[0].iloc[1] / covariance_matrix.iloc[1].iloc[1]\n",
        "alpha = annualized_return - (beta * 365 * benchmark_g_returns.mean())\n",
        "\n",
        "# Compute rolling statistics\n",
        "window = 91  # 3 months\n",
        "# window = 183  # 6 months\n",
        "benchmark_rolling_g_returns = benchmark_g_returns.rolling(window)\n",
        "portfolio_rolling_g_returns = g_returns.rolling(window)\n",
        "benchmark_rolling_volatility = np.sqrt(365 / window) * benchmark_rolling_g_returns.std().dropna()\n",
        "portfolio_rolling_volatility = np.sqrt(365 / window) * portfolio_rolling_g_returns.std().dropna()\n",
        "\n",
        "# Compute asset correlations\n",
        "asset_g_returns = pd.DataFrame(index=trade_dates, columns=tickers)\n",
        "for ticker in tickers:\n",
        "    asset_g_returns[ticker] = np.log(market_data[ticker]['Close Price'].pct_change().dropna() + 1)\n",
        "asset_correlations = asset_g_returns.corr()\n",
        "\n",
        "# Recreate performance using only returns\n",
        "dates = [date for date in trade_dates if date not in cash_flows.keys()]\n",
        "performance = pd.DataFrame(index=dates, columns=['Benchmark (BTC)', 'Portfolio'])\n",
        "start_value = 100000\n",
        "performance['Benchmark (BTC)'].iloc[0] = start_value\n",
        "performance['Portfolio'].iloc[0] = start_value\n",
        "for i in range(len(dates) - 1):\n",
        "    performance['Benchmark (BTC)'].iloc[i + 1] = (benchmark_a_returns.iloc[i] + 1) * \\\n",
        "        performance['Benchmark (BTC)'].iloc[i]\n",
        "    performance['Portfolio'].iloc[i + 1] = (a_returns['Value'].iloc[i] + 1) * performance['Portfolio'].iloc[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXogxQVnrc1t"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "print('STATISTICS')\n",
        "print('---------------------------------------------------------------')\n",
        "print('\\t\\t\\tBenchmark (BTC)\\t\\tPortfolio')\n",
        "print('Total Return\\t\\t%.1f%%\\t\\t\\t%.1f%%' % (100 * benchmark_total_return, 100 * total_return))\n",
        "print('Annualized Return\\t%.1f%%\\t\\t\\t%.1f%%' % (100 * benchmark_annualized_return, 100 * annualized_return))\n",
        "print('Annualized Volatility\\t%.1f%%\\t\\t\\t%.1f%%' % (100 * benchmark_annualized_volatility, \\\n",
        "                                                   100 * annualized_volatility))\n",
        "print('CAGR\\t\\t\\t%.1f%%\\t\\t\\t%.1f%%' % (100 * benchmark_cagr, 100 * cagr))\n",
        "print('Sharpe Ratio\\t\\t%.2f\\t\\t\\t%.2f' % (benchmark_sharpe_ratio, sharpe_ratio))\n",
        "print('Sortino Ratio\\t\\t%.2f\\t\\t\\t%.2f' % (benchmark_sortino_ratio, sortino_ratio))\n",
        "print('Alpha\\t\\t\\tN/A\\t\\t\\t%.1f%%' % (100 * alpha))\n",
        "print('Beta\\t\\t\\tN/A\\t\\t\\t%.1f%%' % (100 * beta))\n",
        "print('---------------------------------------------------------------')\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Simple performance excluding cashflows plot\n",
        "performance.plot(figsize=(12, 8))\n",
        "plt.title('Performance w/o Cashflows')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "# Simple performance with cashflows plot\n",
        "portfolio_performance.plot(figsize=(12, 8))\n",
        "plt.title('Performance w/Cashflows')\n",
        "plt.legend(['Portfolio'])\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "# Asset allocation stacked plot\n",
        "asset_allocation = pd.DataFrame(0, index=trade_dates, columns=tickers)\n",
        "for date, asset_values in asset_performance.items():\n",
        "    total_value = sum(asset_values.values())\n",
        "    for ticker, value in asset_values.items():\n",
        "        asset_allocation[ticker].loc[date] = value / total_value\n",
        "asset_allocation.plot.area(figsize=(12, 8))\n",
        "plt.title('Asset Allocation')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt7FPliprfna"
      },
      "source": [
        "# Rolling volatility chart\n",
        "rolling_volatility = pd.DataFrame(index=portfolio_rolling_volatility.index, \\\n",
        "                                  columns=['Benchmark (BTC)', 'Portfolio'])\n",
        "rolling_volatility['Benchmark (BTC)'] = benchmark_rolling_volatility\n",
        "rolling_volatility['Portfolio'] = portfolio_rolling_volatility\n",
        "rolling_volatility.plot(figsize=(12, 8))\n",
        "plt.title('3 Month Rolling Volatility')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix heatmap\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.set_xticklabels([''] + list(asset_correlations.keys()))\n",
        "ax.set_yticklabels([''] + list(asset_correlations.keys()))\n",
        "cax = ax.matshow(asset_correlations, cmap='bwr', vmin=-1.0, vmax=1.0)\n",
        "for (i, j), z in np.ndenumerate(asset_correlations):\n",
        "    ax.text(j, i, '{:.1f}%'.format(100 * z), ha='center', va='center')\n",
        "plt.title('Correlations')\n",
        "plt.colorbar(cax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJwsWDDhrikN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}